# Node Problem Detector Helm Chart Values
# Based on: https://github.com/kubernetes/node-problem-detector

# Enable the node-problem-detector
enabled: true
# Image configuration
image:
  repository: registry.k8s.io/node-problem-detector
  tag: "v0.9.0"
  pullPolicy: IfNotPresent
# Service account configuration
serviceAccount:
  create: true
  name: "node-problem-detector"
  annotations: {}
# RBAC configuration
rbac:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["nodes"]
      verbs: ["get", "list", "watch", "update", "patch"]
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["create", "patch"]
    - apiGroups: [""]
      resources: ["pods"]
      verbs: ["get", "list", "watch", "delete"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims"]
      verbs: ["get", "list", "watch", "delete"]
    - apiGroups: ["batch"]
      resources: ["jobs"]
      verbs: ["get", "list", "watch", "delete"]
# DaemonSet configuration
daemonSet:
  # Node selector
  nodeSelector: {}
  # Tolerations for control plane nodes
  tolerations:
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: NoSchedule
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule
  # Security context - adjusted for Pod Security Standards
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
  # Resource limits
  resources:
    requests:
      cpu: "50m"
      memory: "50Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"
  # Volume mounts - simplified for security compliance
  volumeMounts:
    - name: localtime
      mountPath: /etc/localtime
      readOnly: true
    - name: custom-config
      mountPath: /config
      readOnly: true
  # Volumes - simplified for security compliance
  volumes:
    - name: localtime
      hostPath:
        path: /etc/localtime
        type: FileOrCreate
    - name: custom-config
      configMap:
        name: node-problem-detector-custom-config
# Configuration for different monitors
config:
  # Kernel monitor configuration - disabled for security
  kernelMonitor:
    enabled: false
  # Docker monitor configuration - disabled for security
  dockerMonitor:
    enabled: false
  # System stats monitor
  systemStatsMonitor:
    enabled: true
    metricsPort: 20257
  # Custom plugin monitor - simplified
  customPluginMonitor:
    enabled: true
    plugins:
      - name: "talos-disk-pressure"
        path: "/custom-plugins/talos-disk-pressure-monitor.sh"
        timeout: "60s"
      - name: "talos-memory-pressure"
        path: "/custom-plugins/talos-memory-pressure-monitor.sh"
        timeout: "60s"
# Service configuration
service:
  enabled: true
  type: ClusterIP
  port: 20256
  targetPort: 20256
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "20257"
    prometheus.io/path: "/metrics"
# Prometheus ServiceMonitor
serviceMonitor:
  enabled: true
  interval: "30s"
  scrapeTimeout: "10s"
  path: "/metrics"
  port: "metrics"
# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "20257"
  prometheus.io/path: "/metrics"
# Pod labels
podLabels:
  app.kubernetes.io/name: node-problem-detector
  app.kubernetes.io/component: monitoring
  app.kubernetes.io/part-of: monitoring-stack
# Custom scripts for Talos monitoring
customScripts:
  talos-disk-pressure-monitor.sh: |
    #!/bin/bash
    # Monitor disk pressure on Talos nodes
    NODE_NAME="$1"

    # Check disk usage using kubectl instead of direct filesystem access
    DISK_USAGE=$(kubectl get nodes $NODE_NAME -o jsonpath='{.status.conditions[?(@.type=="DiskPressure")].status}' 2>/dev/null || echo "Unknown")

    if [ "$DISK_USAGE" = "True" ]; then
      echo "WARNING: Disk pressure detected on $NODE_NAME"
      kubectl create event --type=Warning --reason=DiskPressure --message="Disk pressure detected on node $NODE_NAME" --field-selector involvedObject.name=$NODE_NAME 2>/dev/null || true
    fi
  talos-memory-pressure-monitor.sh: |
    #!/bin/bash
    # Monitor memory pressure on Talos nodes
    NODE_NAME="$1"

    # Check memory pressure using kubectl
    MEMORY_PRESSURE=$(kubectl get nodes $NODE_NAME -o jsonpath='{.status.conditions[?(@.type=="MemoryPressure")].status}' 2>/dev/null || echo "Unknown")

    if [ "$MEMORY_PRESSURE" = "True" ]; then
      echo "WARNING: Memory pressure detected on $NODE_NAME"
      kubectl create event --type=Warning --reason=MemoryPressure --message="Memory pressure detected on node $NODE_NAME" --field-selector involvedObject.name=$NODE_NAME 2>/dev/null || true
    fi
